{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from praw.models import MoreComments\n",
    "sub= 'SteamVR'\n",
    "file = str(sub)+'.csv'\n",
    "reddit = praw.Reddit(\n",
    "    client_id='',     # replace with your client id\n",
    "    client_secret='',  # replace with your client secret\n",
    "    user_agent='',   # replace with your user agent name\n",
    "    username='',       # your reddit username\n",
    "    password=''        # your reddit password\n",
    ")\n",
    "\n",
    "def get_date(submission):\n",
    "    time = submission.created\n",
    "    return datetime.utcfromtimestamp(time)\n",
    "\n",
    "subreddit = reddit.subreddit(str(sub))  # replace with your subreddit name\n",
    "\n",
    "posts = []\n",
    "\n",
    "for submission in subreddit.new(limit=None):\n",
    "    if get_date(submission) < datetime.now() - timedelta(days=180):\n",
    "        break\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "        post = {}\n",
    "        post[\"title\"] = submission.title\n",
    "        post[\"content\"] = submission.selftext\n",
    "        post[\"comment\"] = comment.body\n",
    "        post[\"comment_url\"] = f\"https://www.reddit.com{comment.permalink}\"\n",
    "        post[\"date\"] = get_date(submission)\n",
    "        posts.append(post)\n",
    "\n",
    "keys = [\"title\", \"content\", \"comment\", \"comment_url\", \"date\"]\n",
    "\n",
    "with open(file, 'w', newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from cleantext import clean\n",
    "\n",
    "# load csv file\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "def preprocess_comments(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Remove emojis\n",
    "    text = clean(text, no_emoji=True)\n",
    "\n",
    "    # Set a limit of minimum 5 and maximum 3000 characters\n",
    "    if len(text) < 40 or len(text) > 3000:\n",
    "        return None\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply preprocessing function to 'comment' column\n",
    "df['comment'] = df['comment'].apply(preprocess_comments)\n",
    "\n",
    "# Remove rows with empty comments\n",
    "df = df.dropna(subset=['comment'])\n",
    "#Remove duplicates\n",
    "df = df.drop_duplicates(subset='comment')\n",
    "\n",
    "# Save the DataFrame to CSV file\n",
    "df.to_csv(file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
